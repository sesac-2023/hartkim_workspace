{"cells":[{"cell_type":"markdown","metadata":{"id":"hcDpkPWlgLTM"},"source":["CUDA 버전 확인하기\n","\n","- !nvidia-smi\n","- !nvcc --version\n","\n","둘의 차이점은\n","nvidia-smi는 해당 장치에서 설치 가능한 가장 높은 버전을 보여주고,\n","nvcc --version은 현재 설치된 cuda 버전을 보여줌\n","\n","출처 : https://stackoverflow.com/questions/9727688/how-to-get-the-cuda-version"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xBjhMOvSgAZH"},"outputs":[],"source":["!nvcc --version"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ttqUGq2AgKk7"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"epE_X6qbyoQ0","outputId":"35b9eabd-4cc6-4a51-edc3-5f2a69dce7bc","executionInfo":{"status":"ok","timestamp":1689820387325,"user_tz":-540,"elapsed":3906,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.1+cu118\n"]}],"source":["# PyTorch 2.x 버전 설치\n","try:\n","    # 기본적으로 https://pytorch.kr/get-started/locally/ 에서\n","    # cuda 버전과 패키지매니저에 맞는 설치 명령어를 확인 가능\n","    # %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","    import torch\n","    print(torch.__version__)\n","except:\n","    pass"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Cxz1VK5-iQCJ","executionInfo":{"status":"ok","timestamp":1689820387616,"user_tz":-540,"elapsed":294,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["# pytorch에서 사용할 함수들 호출하기\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.optim.lr_scheduler import StepLR"]},{"cell_type":"markdown","metadata":{"id":"dwr6-f65iUA_"},"source":["----------------------------------------------------------\n","\n","# CNN 으로 이미지 분석하기"]},{"cell_type":"markdown","metadata":{"id":"_gjojIGLhALq"},"source":["## ****1. Mnist 데이터로 Convolution2D로 구현하기****"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z92u1WATiWRh"},"outputs":[],"source":["train_dataset = datasets.MNIST('./data', train=True, download=True)"]},{"cell_type":"code","source":["train_dataset[10004]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"98TI3Y6PJWRJ","executionInfo":{"status":"ok","timestamp":1689820433259,"user_tz":-540,"elapsed":10,"user":{"displayName":"최재진","userId":"14104918437285699837"}},"outputId":"1cf1072d-33ab-4b55-bd1a-08122b4a9dcc"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<PIL.Image.Image image mode=L size=28x28 at 0x78097C0DBC40>, 9)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Bpqxh_NiY43"},"outputs":[],"source":["train_dataset[10004][0].resize((280, 280))"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":430},"id":"iAm3AJMei6hf","outputId":"15199c9b-0303-4ced-9564-5941487c3698","executionInfo":{"status":"ok","timestamp":1689820513514,"user_tz":-540,"elapsed":424,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["from matplotlib import pyplot as plt\n","\n","plt.figure()\n","plt.imshow(train_dataset[10004][0], cmap=plt.cm.binary)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"_j4wVCEKkWRs"},"source":["## 2. 이미지를 학습시키기 위한 처리\n","\n","1. ToTensor: 이미지를 학습이 가능하도록 숫자화한다. (Image, np,ndarray[W, H, C] -> tensor[C, W, H])\n","https://pytorch.org/vision/stable/generated/torchvision.transforms.ToTensor.html\n","\n","2. Normalize: CNN 성능을 높이기 위한 처리 (채널별로 각각 다른 평균, 분산을 적용 가능하다.)\n","https://pytorch.org/vision/main/generated/torchvision.transforms.Normalize.html"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"o3SigPXvi_Yo","executionInfo":{"status":"ok","timestamp":1689820595718,"user_tz":-540,"elapsed":273,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["# 이미지를 학습이 가능하도록 숫자화\n","to_tensor = transforms.ToTensor()"]},{"cell_type":"code","source":["type(train_dataset[10004][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"40iJQFsSKCCP","executionInfo":{"status":"ok","timestamp":1689820610810,"user_tz":-540,"elapsed":2,"user":{"displayName":"최재진","userId":"14104918437285699837"}},"outputId":"c9e52102-3eb5-4201-ceca-908fc7d84e77"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["PIL.Image.Image"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Z1w18alEjO8-","executionInfo":{"status":"ok","timestamp":1689820618220,"user_tz":-540,"elapsed":2,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["image_tensor = to_tensor(train_dataset[10004][0])"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_7pfI8SzjqMC","outputId":"7d5c0f5c-5318-4515-9721-9ff81869ebfb","executionInfo":{"status":"ok","timestamp":1689820618550,"user_tz":-540,"elapsed":2,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 28, 28])"]},"metadata":{},"execution_count":14}],"source":["image_tensor.shape"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"KXmXv3p8jj8J","executionInfo":{"status":"ok","timestamp":1689820640623,"user_tz":-540,"elapsed":368,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["# 단일 채널이므로 하나의 채널에만 평균 0.1307, 분산 0.3081로 조정한다.\n","normalizer = transforms.Normalize((0.1307,), (0.3081,))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jBGZPgHtjVE9"},"outputs":[],"source":["normalizer(image_tensor)"]},{"cell_type":"markdown","metadata":{"id":"r1mnmqNIlGiP"},"source":["알아서 적용할수는 없을까?\n","\n","-> 당연히 있다.\n","\n","transforms.Compose([  \n","&nbsp;&nbsp;&nbsp;&nbsp;적용할 변형들  \n","])"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"wsFnL22AjsaE","executionInfo":{"status":"ok","timestamp":1689820684553,"user_tz":-540,"elapsed":364,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307, ), (0.3081, ))\n","])"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"MU2ALUS_m1Bg","executionInfo":{"status":"ok","timestamp":1689820689565,"user_tz":-540,"elapsed":263,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["# train_dataset에 transform 적용\n","train_dataset.transform = transform"]},{"cell_type":"markdown","metadata":{"id":"zQH4gxM2l2sU"},"source":["## DataLoader 생성\n","\n","- PyTorch는 모델을 학습시킬 때 batch_size만큼 데이터를 뽑아서 Dataset의 처리를 진행한 뒤 모델에 주입한다.\n","- 지금은 Dataset을 커스텀하여 사용하지 않고 있지만, 이러한 처리를 DataLoader가 해준다는 것은 분명 큰 이점이다.\n","- n_workers 옵션은 이를 병렬적으로 수행 가능하게 한다."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"rggOE4WJlvLX","executionInfo":{"status":"ok","timestamp":1689820771522,"user_tz":-540,"elapsed":268,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"gCkIon89m35X"},"source":["## 모델 구축"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"yRj49WjnlvA1","executionInfo":{"status":"ok","timestamp":1689821457136,"user_tz":-540,"elapsed":267,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["class MyCNN(nn.Module):\n","    def __init__(self):\n","        super(MyCNN, self).__init__()\n","\n","        # self.name\n","        self.conv = nn.Sequential(\n","            # 28x28x1\n","            nn.Conv2d(1, 64, 3, 1), # input channel, output channel, kernel_size, stride(, padding)\n","            # 26x26x64\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2),\n","            # 13x13x64\n","            nn.Conv2d(64, 128, 3, 1),\n","            # 11x11x128\n","            nn.ReLU(True),\n","            nn.MaxPool2d(2),\n","            # 5x5x128\n","            nn.Conv2d(128, 256, 3, 1),\n","            # 3x3x256\n","            nn.ReLU(True),)\n","        self.classification = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(2304, 32), # 2304\n","            nn.ReLU(True),\n","            nn.Linear(32, 10),\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        output = self.classification(x)\n","        # output = self.model(x)\n","        return output"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"Ppb5lsgToreT","executionInfo":{"status":"ok","timestamp":1689821457450,"user_tz":-540,"elapsed":2,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["cnn = MyCNN()"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9KobaG09pV5D","outputId":"376eeb70-ecb1-4aa1-d767-f3b3133183b6","executionInfo":{"status":"ok","timestamp":1689821458025,"user_tz":-540,"elapsed":3,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["MyCNN(\n","  (conv): Sequential(\n","    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n","    (7): ReLU(inplace=True)\n","  )\n","  (classification): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=2304, out_features=32, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Linear(in_features=32, out_features=10, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":28}],"source":["cnn"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"th9sHn_VpmHm","executionInfo":{"status":"ok","timestamp":1689821492305,"user_tz":-540,"elapsed":5301,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["# 모델 학습을 위한 옵티마이저와 스케줄러 정의\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","cnn.to(device)\n","\n","# loss를 multiclass 분류에 적합한 loss인 cross entropy loss를 사용\n","criterion = nn.CrossEntropyLoss().cuda()\n","\n","optimizer = optim.Adadelta(cnn.parameters(), lr=1.0)\n","scheduler = StepLR(optimizer, step_size=1, gamma=0.7)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"J_igsgoOp_2W","executionInfo":{"status":"ok","timestamp":1689821524795,"user_tz":-540,"elapsed":283,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"JBOou4KEpvbf","outputId":"8a5d95df-4b4d-4583-91f4-90bf0c4c95fb","executionInfo":{"status":"error","timestamp":1689821719294,"user_tz":-540,"elapsed":97909,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.282621\n","Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.165553\n","Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.148685\n","Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.024493\n","Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.212915\n","Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.003334\n","Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.048035\n","Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.003804\n","Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.042904\n","Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.021742\n","Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.002516\n","Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.019883\n","Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.090553\n","Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.494724\n","Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.001670\n","Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.006083\n","Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.086085\n","Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.010369\n","Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.052997\n","\n","Test set: Average loss: 0.0012, Accuracy: 9881/10000 (99%)\n","\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.000444\n","Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.074064\n","Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.001150\n","Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.017434\n","Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.024281\n","Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.110930\n","Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.003587\n","Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.002035\n","Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.022670\n","Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.008125\n","Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.002117\n","Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.016802\n","Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.000629\n","Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.186542\n","Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.001359\n","Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.000967\n","Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.000320\n","Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.032471\n","Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.000347\n","\n","Test set: Average loss: 0.0008, Accuracy: 9917/10000 (99%)\n","\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.001297\n","Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.001944\n","Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.000065\n","Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.000750\n","Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.001106\n","Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.013480\n","Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.000175\n","Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.004805\n","Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.157147\n","Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.005732\n","Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.000086\n","Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.001687\n","Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.000467\n","Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.000285\n","Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.002027\n","Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.000090\n","Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.000048\n","Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.001029\n","Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.000081\n","\n","Test set: Average loss: 0.0008, Accuracy: 9928/10000 (99%)\n","\n","Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.000005\n","Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.001928\n","Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.000106\n","Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.005084\n","Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.000119\n","Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.000049\n","Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.000195\n","Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.002895\n","Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.000101\n","Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.000096\n","Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.000002\n","Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.000033\n","Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.000001\n","Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.000236\n","Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.004750\n","Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.000054\n","Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.000138\n","Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.001265\n","Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.000003\n","\n","Test set: Average loss: 0.0007, Accuracy: 9938/10000 (99%)\n","\n","Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.006232\n","Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.000026\n","Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.000031\n","Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.000761\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-3f98d99cad84>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# 학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# 모델 학습 (tensorflow는 fit 하나로 아래의 과정을 처리한다.)\n","epochs = 10\n","dry_run = False # 1 배치만 훈련\n","\n","for epoch in range(1, epochs+1):\n","    # 학습\n","    cnn.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = cnn(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % 100 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))\n","            if dry_run:\n","                break\n","\n","    # 테스트\n","    cnn.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = cnn(data)\n","            test_loss += criterion(output, target).detach().sum()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","\n","    scheduler.step()"]},{"cell_type":"markdown","metadata":{"id":"9hjfbjFgRD_Q"},"source":["### 모델의 구조를 이해해보자.  \n","output shape : 피처맵의 크기 * 채널  \n","param : weight의 개수"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vuvhd8JimLD2","outputId":"007d9838-f3f1-4851-f3e3-145bd9710adb","executionInfo":{"status":"ok","timestamp":1689821884640,"user_tz":-540,"elapsed":8337,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n"]},{"output_type":"execute_result","data":{"text/plain":["=================================================================\n","Layer (type:depth-idx)                   Param #\n","=================================================================\n","MyCNN                                    --\n","├─Sequential: 1-1                        --\n","│    └─Conv2d: 2-1                       640\n","│    └─ReLU: 2-2                         --\n","│    └─MaxPool2d: 2-3                    --\n","│    └─Conv2d: 2-4                       73,856\n","│    └─ReLU: 2-5                         --\n","│    └─MaxPool2d: 2-6                    --\n","│    └─Conv2d: 2-7                       295,168\n","│    └─ReLU: 2-8                         --\n","├─Sequential: 1-2                        --\n","│    └─Flatten: 2-9                      --\n","│    └─Linear: 2-10                      73,760\n","│    └─ReLU: 2-11                        --\n","│    └─Linear: 2-12                      330\n","=================================================================\n","Total params: 443,754\n","Trainable params: 443,754\n","Non-trainable params: 0\n","================================================================="]},"metadata":{},"execution_count":33}],"source":["# %pip install torchinfo\n","from torchinfo import summary\n","summary(cnn)\n","\n","# ouptut image의 크기는?\n","# 가중치의 개수는?"]},{"cell_type":"code","source":["# in = 1, out = 64, kernel 3\n","(3*3*1+1)*64 = 640\n","# in = 64 out = 128, kernel 3\n","(3*3*64+1) * 128 = 73856\n","# in = 128 out = 256 kernel 3\n","(3*3*128+1) * 256 = 295168\n","\n","2304 -> 32\n","73,760\n","32 -> 10\n"],"metadata":{"id":"B3GYAGwWPLQO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5L6cxsi-WkAP"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"plwI0ZU5qmTY"},"source":["## ****2.cifar10 데이터로 Convolution2D로 구현해보기****"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SdV8t4GOrdCk"},"outputs":[],"source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","batch_size = 32\n","\n","train_dataset = datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n","                                          shuffle=True, num_workers=2)\n","\n","test_dataset = datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n","                                         shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer',\n","           'dog', 'frog', 'horse', 'ship', 'truck')"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"53B-1KPgsttr","outputId":"6266f038-0f25-46fa-881c-a0287ce6e48a","executionInfo":{"status":"ok","timestamp":1689822452243,"user_tz":-540,"elapsed":276,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 32, 32])"]},"metadata":{},"execution_count":36}],"source":["train_dataset[0][0].shape"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"OqVFzO87tgVU","executionInfo":{"status":"ok","timestamp":1689822467918,"user_tz":-540,"elapsed":271,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["# 역정규화\n","denormalize = transforms.Compose([\n","     transforms.Normalize((0., 0., 0.), (1/0.5, 1/0.5, 1/0.5)),\n","     transforms.Normalize((-0.5, -0.5, -0.5), (1., 1., 1.)),\n","     ])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xz0LGJectU70"},"outputs":[],"source":["i = 5\n","denormalize(train_dataset[i][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZD9ok0qsrtZj"},"outputs":[],"source":["plt.figure(figsize=(20,20))\n","for i in range(100):\n","    plt.subplot(10,10,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.imshow(denormalize(train_dataset[i][0]).permute(1, 2, 0)) # C, W, H -> W, H, C\n","    plt.xlabel(classes[train_dataset[i][1]])\n","plt.show()"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"bggFDpoZsKmd","executionInfo":{"status":"ok","timestamp":1689823008653,"user_tz":-540,"elapsed":256,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["class MyCNN(nn.Module):\n","    def __init__(self):\n","        super(MyCNN, self).__init__()\n","\n","        # self.name\n","        # 각 이미지의 크기는 어떻게 변할까?\n","        self.convolution = nn.Sequential(\n","            # 3x32x32\n","            nn.Conv2d(3, 64, 3, 1), # weight 수? (3*3*3+1) * 64\n","            # 64x30x30\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            # 64x15x15\n","            nn.Conv2d(64, 128, 3, 1), # (3*3*64+1) * 128\n","            # 128x13x13\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            # 128x6x6\n","            nn.Conv2d(128, 256, 3, 1), # (3*3*128+1) * 256\n","            # 256x4x4\n","            nn.ReLU(),)\n","\n","        self.fully_connected = nn.Sequential(\n","            nn.Linear(4096, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 10),\n","        )\n","\n","    def forward(self, x):\n","        x = self.convolution(x)\n","        x = torch.flatten(x, 1)\n","        output = self.fully_connected(x)\n","        return output"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"O-FWEwoMv7ei","executionInfo":{"status":"ok","timestamp":1689823010516,"user_tz":-540,"elapsed":5,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["model = MyCNN()"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FsZ0KudKv9vw","outputId":"0ea57932-80b0-4376-d98f-bc6ab5a237d1","executionInfo":{"status":"ok","timestamp":1689823011979,"user_tz":-540,"elapsed":4,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["MyCNN(\n","  (convolution): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n","    (4): ReLU()\n","    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n","    (7): ReLU()\n","  )\n","  (fully_connected): Sequential(\n","    (0): Linear(in_features=4096, out_features=128, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=128, out_features=10, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":42}],"source":["model"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U3ffXM64wAJW","outputId":"85278d82-aa5e-4b86-d271-393faae728ab","executionInfo":{"status":"ok","timestamp":1689823023044,"user_tz":-540,"elapsed":275,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["=================================================================\n","Layer (type:depth-idx)                   Param #\n","=================================================================\n","MyCNN                                    --\n","├─Sequential: 1-1                        --\n","│    └─Conv2d: 2-1                       1,792\n","│    └─ReLU: 2-2                         --\n","│    └─MaxPool2d: 2-3                    --\n","│    └─Conv2d: 2-4                       73,856\n","│    └─ReLU: 2-5                         --\n","│    └─MaxPool2d: 2-6                    --\n","│    └─Conv2d: 2-7                       295,168\n","│    └─ReLU: 2-8                         --\n","├─Sequential: 1-2                        --\n","│    └─Linear: 2-9                       524,416\n","│    └─ReLU: 2-10                        --\n","│    └─Linear: 2-11                      1,290\n","=================================================================\n","Total params: 896,522\n","Trainable params: 896,522\n","Non-trainable params: 0\n","================================================================="]},"metadata":{},"execution_count":43}],"source":["from torchinfo import summary\n","summary(model)"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"z2qhHSdwwDfd","executionInfo":{"status":"ok","timestamp":1689823048210,"user_tz":-540,"elapsed":289,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["# 모델 학습을 위한 옵티마이저와 스케줄러 정의\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss().cuda()\n","\n","optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n","scheduler = StepLR(optimizer, step_size=1, gamma=0.7)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YBLId1UrwTG-","outputId":"37792927-aaa3-4d89-e4cc-bd6ae44936de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.308794\n","Train Epoch: 1 [3200/50000 (6%)]\tLoss: 1.934421\n","Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.686767\n","Train Epoch: 1 [9600/50000 (19%)]\tLoss: 1.382667\n","Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.846850\n","Train Epoch: 1 [16000/50000 (32%)]\tLoss: 1.588354\n","Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.207009\n","Train Epoch: 1 [22400/50000 (45%)]\tLoss: 1.282934\n","Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.503977\n","Train Epoch: 1 [28800/50000 (58%)]\tLoss: 1.335378\n","Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.016386\n","Train Epoch: 1 [35200/50000 (70%)]\tLoss: 1.102322\n","Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.120662\n","Train Epoch: 1 [41600/50000 (83%)]\tLoss: 0.943088\n","Train Epoch: 1 [44800/50000 (90%)]\tLoss: 1.386589\n","Train Epoch: 1 [48000/50000 (96%)]\tLoss: 0.859497\n","\n","Test set: Average loss: 0.0359, Accuracy: 5966/10000 (60%)\n","\n","Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.859941\n","Train Epoch: 2 [3200/50000 (6%)]\tLoss: 0.814388\n","Train Epoch: 2 [6400/50000 (13%)]\tLoss: 0.920877\n","Train Epoch: 2 [9600/50000 (19%)]\tLoss: 1.045293\n","Train Epoch: 2 [12800/50000 (26%)]\tLoss: 0.992501\n","Train Epoch: 2 [16000/50000 (32%)]\tLoss: 0.808829\n","Train Epoch: 2 [19200/50000 (38%)]\tLoss: 0.901870\n","Train Epoch: 2 [22400/50000 (45%)]\tLoss: 1.172782\n","Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.157890\n","Train Epoch: 2 [28800/50000 (58%)]\tLoss: 0.675085\n","Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.681062\n","Train Epoch: 2 [35200/50000 (70%)]\tLoss: 0.700311\n","Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.880297\n","Train Epoch: 2 [41600/50000 (83%)]\tLoss: 0.890179\n","Train Epoch: 2 [44800/50000 (90%)]\tLoss: 0.842422\n","Train Epoch: 2 [48000/50000 (96%)]\tLoss: 0.696562\n","\n","Test set: Average loss: 0.0325, Accuracy: 6495/10000 (65%)\n","\n","Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.739772\n","Train Epoch: 3 [3200/50000 (6%)]\tLoss: 0.677526\n","Train Epoch: 3 [6400/50000 (13%)]\tLoss: 0.731669\n","Train Epoch: 3 [9600/50000 (19%)]\tLoss: 0.851059\n","Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.726778\n","Train Epoch: 3 [16000/50000 (32%)]\tLoss: 0.938719\n","Train Epoch: 3 [19200/50000 (38%)]\tLoss: 0.701742\n","Train Epoch: 3 [22400/50000 (45%)]\tLoss: 0.564936\n","Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.762835\n","Train Epoch: 3 [28800/50000 (58%)]\tLoss: 0.574410\n","Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.470601\n","Train Epoch: 3 [35200/50000 (70%)]\tLoss: 0.715647\n","Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.939538\n","Train Epoch: 3 [41600/50000 (83%)]\tLoss: 0.547708\n","Train Epoch: 3 [44800/50000 (90%)]\tLoss: 0.472743\n","Train Epoch: 3 [48000/50000 (96%)]\tLoss: 0.759664\n","\n","Test set: Average loss: 0.0239, Accuracy: 7436/10000 (74%)\n","\n","Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.449963\n","Train Epoch: 4 [3200/50000 (6%)]\tLoss: 0.432946\n","Train Epoch: 4 [6400/50000 (13%)]\tLoss: 0.348929\n","Train Epoch: 4 [9600/50000 (19%)]\tLoss: 0.594747\n","Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.439488\n","Train Epoch: 4 [16000/50000 (32%)]\tLoss: 0.634411\n","Train Epoch: 4 [19200/50000 (38%)]\tLoss: 0.339988\n","Train Epoch: 4 [22400/50000 (45%)]\tLoss: 0.334158\n","Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.445108\n","Train Epoch: 4 [28800/50000 (58%)]\tLoss: 0.430028\n","Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.507161\n","Train Epoch: 4 [35200/50000 (70%)]\tLoss: 0.483867\n","Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.368273\n","Train Epoch: 4 [41600/50000 (83%)]\tLoss: 0.398009\n","Train Epoch: 4 [44800/50000 (90%)]\tLoss: 0.489795\n","Train Epoch: 4 [48000/50000 (96%)]\tLoss: 0.584208\n","\n","Test set: Average loss: 0.0237, Accuracy: 7655/10000 (77%)\n","\n","Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.358237\n","Train Epoch: 5 [3200/50000 (6%)]\tLoss: 0.164565\n","Train Epoch: 5 [6400/50000 (13%)]\tLoss: 0.093184\n","Train Epoch: 5 [9600/50000 (19%)]\tLoss: 0.245005\n","Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.161718\n","Train Epoch: 5 [16000/50000 (32%)]\tLoss: 0.234824\n","Train Epoch: 5 [19200/50000 (38%)]\tLoss: 0.275141\n","Train Epoch: 5 [22400/50000 (45%)]\tLoss: 0.273095\n","Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.195820\n","Train Epoch: 5 [28800/50000 (58%)]\tLoss: 0.290521\n","Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.349162\n","Train Epoch: 5 [35200/50000 (70%)]\tLoss: 0.264669\n","Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.244411\n","Train Epoch: 5 [41600/50000 (83%)]\tLoss: 0.261271\n","Train Epoch: 5 [44800/50000 (90%)]\tLoss: 0.284343\n","Train Epoch: 5 [48000/50000 (96%)]\tLoss: 0.176317\n","\n","Test set: Average loss: 0.0252, Accuracy: 7692/10000 (77%)\n","\n","Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.274627\n","Train Epoch: 6 [3200/50000 (6%)]\tLoss: 0.423646\n","Train Epoch: 6 [6400/50000 (13%)]\tLoss: 0.118644\n","Train Epoch: 6 [9600/50000 (19%)]\tLoss: 0.437645\n","Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.131853\n","Train Epoch: 6 [16000/50000 (32%)]\tLoss: 0.085626\n","Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.124663\n","Train Epoch: 6 [22400/50000 (45%)]\tLoss: 0.187773\n","Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.081367\n","Train Epoch: 6 [28800/50000 (58%)]\tLoss: 0.054895\n","Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.332466\n","Train Epoch: 6 [35200/50000 (70%)]\tLoss: 0.082115\n","Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.394469\n","Train Epoch: 6 [41600/50000 (83%)]\tLoss: 0.139317\n","Train Epoch: 6 [44800/50000 (90%)]\tLoss: 0.116483\n","Train Epoch: 6 [48000/50000 (96%)]\tLoss: 0.080008\n","\n","Test set: Average loss: 0.0269, Accuracy: 7737/10000 (77%)\n","\n","Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.154405\n","Train Epoch: 7 [3200/50000 (6%)]\tLoss: 0.113741\n","Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.234129\n","Train Epoch: 7 [9600/50000 (19%)]\tLoss: 0.253172\n","Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.132478\n","Train Epoch: 7 [16000/50000 (32%)]\tLoss: 0.044531\n","Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.247780\n","Train Epoch: 7 [22400/50000 (45%)]\tLoss: 0.028761\n","Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.064342\n","Train Epoch: 7 [28800/50000 (58%)]\tLoss: 0.087887\n","Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.164143\n","Train Epoch: 7 [35200/50000 (70%)]\tLoss: 0.341447\n","Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.154714\n","Train Epoch: 7 [41600/50000 (83%)]\tLoss: 0.196270\n","Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.122658\n","Train Epoch: 7 [48000/50000 (96%)]\tLoss: 0.159459\n","\n","Test set: Average loss: 0.0296, Accuracy: 7766/10000 (78%)\n","\n","Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.045965\n","Train Epoch: 8 [3200/50000 (6%)]\tLoss: 0.259986\n","Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.114382\n","Train Epoch: 8 [9600/50000 (19%)]\tLoss: 0.026221\n","Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.063254\n","Train Epoch: 8 [16000/50000 (32%)]\tLoss: 0.169183\n","Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.157251\n","Train Epoch: 8 [22400/50000 (45%)]\tLoss: 0.016704\n","Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.083450\n","Train Epoch: 8 [28800/50000 (58%)]\tLoss: 0.023130\n","Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.030813\n","Train Epoch: 8 [35200/50000 (70%)]\tLoss: 0.023164\n","Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.048221\n","Train Epoch: 8 [41600/50000 (83%)]\tLoss: 0.026780\n","Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.019375\n","Train Epoch: 8 [48000/50000 (96%)]\tLoss: 0.089841\n"]}],"source":["# 모델 학습 (tensorflow는 fit 하나로 아래의 과정을 처리한다.)\n","epochs = 10\n","dry_run = False # 1 배치만 훈련\n","\n","for epoch in range(1, epochs+1):\n","    # 학습\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(trainloader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % 100 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(trainloader.dataset),\n","                100. * batch_idx / len(trainloader), loss.item()))\n","            if dry_run:\n","                break\n","\n","    # 테스트\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in testloader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += criterion(output, target).detach().sum()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(testloader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(testloader.dataset),\n","        100. * correct / len(testloader.dataset)))\n","\n","    scheduler.step()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SX7GDka1wVk0"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"XzluHCQCipXm"},"source":["### CNN 응용모델들\n","\n","https://pytorch.org/vision/stable/models.html"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4bWY0yV_w7aZ"},"outputs":[],"source":["import torchvision.models as tc_models\n","print(dir(tc_models))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FQLRAnHryCxj"},"outputs":[],"source":["resnet = tc_models.resnet50(weights=\"IMAGENET1K_V2\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yeJjeMF4yKu-"},"outputs":[],"source":["resnet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JC0a9FqxyZUZ"},"outputs":[],"source":["resnet = tc_models.resnet50(weights=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WN75b0Lnycs8"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SaDUyuPAxmFA"},"outputs":[],"source":["import torch\n","\n","# Option 1: passing weights param as string\n","model = torch.hub.load(\"pytorch/vision\", \"resnet50\", weights=\"IMAGENET1K_V2\")\n","\n","# # Option 2: passing weights param as enum\n","# weights = torch.hub.load(\"pytorch/vision\", \"get_weight\", weights=\"ResNet50_Weights.IMAGENET1K_V2\")\n","# model = torch.hub.load(\"pytorch/vision\", \"resnet50\", weights=weights)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FYnQFWrLlAHT"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}