{"cells":[{"cell_type":"markdown","metadata":{"id":"hcDpkPWlgLTM"},"source":["### CUDA 버전 확인하기\n","\n","- !nvidia-smi\n","- !nvcc --version\n","\n","둘의 차이점은\n","nvidia-smi는 해당 장치에서 설치 가능한 가장 높은 버전을 보여주고,\n","nvcc --version은 현재 설치된 cuda 버전을 보여줌\n","\n","출처 : https://stackoverflow.com/questions/9727688/how-to-get-the-cuda-version"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"xBjhMOvSgAZH","executionInfo":{"status":"ok","timestamp":1689828900655,"user_tz":-540,"elapsed":310,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["gpu_info = !nvcc --version"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kxr_SAY-zRfH","outputId":"f77cd894-f95a-4bfc-cbda-36ad888b67b8","executionInfo":{"status":"ok","timestamp":1689828905040,"user_tz":-540,"elapsed":306,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2022 NVIDIA Corporation\n","Built on Wed_Sep_21_10:33:58_PDT_2022\n","Cuda compilation tools, release 11.8, V11.8.89\n","Build cuda_11.8.r11.8/compiler.31833905_0\n"]}],"source":["gpu_info = '\\n'.join(gpu_info)\n","print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ttqUGq2AgKk7"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"epE_X6qbyoQ0","outputId":"9b71061d-7ad7-4e1d-e4c4-65d6229a3083","executionInfo":{"status":"ok","timestamp":1689832957555,"user_tz":-540,"elapsed":5772,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.1+cu118\n"]}],"source":["# PyTorch 2.x 버전 설치\n","try:\n","    # 기본적으로 https://pytorch.kr/get-started/locally/ 에서\n","    # cuda 버전과 패키지매니저에 맞는 설치 명령어를 확인 가능\n","    # %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","    import torch\n","    print(torch.__version__)\n","except:\n","    pass"]},{"cell_type":"markdown","metadata":{"id":"dwr6-f65iUA_"},"source":["----------------------------------------------------------\n","\n","# VGGNet 직접 구현하기"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Cxz1VK5-iQCJ","executionInfo":{"status":"ok","timestamp":1689832958000,"user_tz":-540,"elapsed":451,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["# pytorch에서 사용할 함수들 호출하기\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.optim.lr_scheduler import StepLR"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HD6OWIBdzYIJ","outputId":"61c936c2-4717-45fe-e7dd-8352f616a103","executionInfo":{"status":"ok","timestamp":1689829310770,"user_tz":-540,"elapsed":356309,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./data/stl10_binary.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2640397119/2640397119 [05:09<00:00, 8518833.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/stl10_binary.tar.gz to ./data\n","Files already downloaded and verified\n"]}],"source":["# 데이터가 상당히 크기 때문에 시간이 좀 소요됨\n","transform = transforms.Compose([\n","    transforms.Resize(72),\n","    transforms.RandomCrop(56),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5 ), (0.5, 0.5, 0.5 )),\n","])\n","\n","train_dataset = datasets.STL10(root='./data', split='train', download=True, transform=transform)\n","# train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)\n","\n","test_dataset = datasets.STL10(root='./data', split='test', download=True, transform=transform)\n","# test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False)"]},{"cell_type":"code","source":["nn."],"metadata":{"id":"Hc2nfSCI3Uaz"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"kSzu-cbjzir3","executionInfo":{"status":"ok","timestamp":1689832958000,"user_tz":-540,"elapsed":2,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["class VGGNet11(nn.Module):\n","\n","    def __init__(self, num_classes=10):\n","        super(VGGNet11, self).__init__()\n","        self.convnet = nn.Sequential(\n","            # 여기에 CNN 모델을 구현해주세요.\n","            # 파라미터가 많아지면 헷갈리기 때문에, 파라미터 이름을 주는것도 좋음\n","            # input image size = 3, 56, 56\n","            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n","            # 64, 56, 56\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            # 64, 28, 28\n","\n","            nn.Conv2d(64, 128, 3, 1, 1),\n","            # 128, 28, 28\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            # 128, 14, 14\n","\n","            nn.Conv2d(128, 256, 3, 1, 1),\n","            # 256, 14, 14\n","            nn.ReLU(),\n","            nn.Conv2d(256, 256, 3, 1, 1),\n","            # 256, 14, 14\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            # 256, 7, 7,\n","\n","            nn.Conv2d(256, 512, 3, 1, 1),\n","            # 512, 7, 7\n","            nn.ReLU(),\n","            nn.Conv2d(512, 512, 3, 1, 1),\n","            # 512, 7, 7\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            # 512, 3, 3,\n","            nn.Conv2d(512, 512, 3, 1, 1),\n","            # 512, 3, 3\n","            nn.ReLU(),\n","            nn.Conv2d(512, 512, 3, 1, 1),\n","            # 512, 3, 3\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            # 512, 1, 1,\n","\n","        )\n","\n","        self.fclayer = nn.Sequential(\n","            # 여기에 FC 모델을 구현해주세요.\n","            nn.Flatten(),\n","            nn.Linear(512, num_classes),\n","        )\n","\n","    def forward(self, x):\n","        x = self.convnet(x)\n","        # x = torch.flatten(x, 1)\n","        output = self.fclayer(x)\n","        return output"]},{"cell_type":"code","source":["class VGGNet13(nn.Module):\n","    def __init__(self,) :\n","        super(VGGNet13, self).__init__()\n","\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(),\n","\n","        )\n","\n","    def forward(self, x):\n","\n","        return x"],"metadata":{"id":"NB1cV2Wg5Zcu"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"JemPQZpt2rx6","executionInfo":{"status":"ok","timestamp":1689832958923,"user_tz":-540,"elapsed":6,"user":{"displayName":"최재진","userId":"14104918437285699837"}}},"outputs":[],"source":["model = VGGNet11(num_classes=10)"]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lOGaJQg45LO8","executionInfo":{"status":"ok","timestamp":1689832963963,"user_tz":-540,"elapsed":6,"user":{"displayName":"최재진","userId":"14104918437285699837"}},"outputId":"c66130c5-cc50-4757-f692-c75e0731500e"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VGGNet11(\n","  (convnet): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): ReLU()\n","    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU()\n","    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU()\n","    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (12): ReLU()\n","    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (14): ReLU()\n","    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (17): ReLU()\n","    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (19): ReLU()\n","    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (fclayer): Sequential(\n","    (0): Flatten(start_dim=1, end_dim=-1)\n","    (1): Linear(in_features=512, out_features=10, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cA6zUQHj27kU"},"outputs":[],"source":["# 학습을 위한 설정\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss().cuda()\n","optimizer = optim.Adam(model.parameters(),lr=1e-5)\n","scheduler = StepLR(optimizer, step_size=30, gamma=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bmw2gd4c2t1D"},"outputs":[],"source":["# 모델 학습\n","epochs = 40\n","dry_run = False # 1 배치만 훈련\n","\n","for epoch in range(1, epochs+1):\n","    # 학습\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % 10 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.detach().cpu().item()))\n","            if dry_run:\n","                break\n","\n","    # 테스트\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","\n","    for data, target in test_loader:\n","        data, target = data.to(device), target.to(device)\n","        with torch.no_grad():\n","            output = model(data)\n","        test_loss += criterion(output, target).detach().cpu().item()\n","        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","\n","    scheduler.step()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EItCxBNK4vNX"},"outputs":[],"source":["for name, param in model.named_parameters():\n","    print(name)\n","    print(param)\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h-yoBT2_WLsO"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}